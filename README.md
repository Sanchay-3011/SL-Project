# SL Project 

A **Sign Language to Text and Speech Conversion System** built using **OpenCV, Mediapipe, and Machine Learning**.  
This project aims to bridge the communication gap between the hearing-impaired community and others by translating sign language gestures into text and speech in real time.

---

## ğŸš€ Features
- ğŸ“· **Real-time Hand Gesture Detection** using OpenCV and Mediapipe  
- ğŸ”¤ **Alphabet & Gesture Recognition** with a trained ML model  
- ğŸ”Š **Text-to-Speech Conversion** for predicted characters/words  
- ğŸ“ **Live Text Display** of recognized signs  
- ğŸ¯ Easy-to-use interface and lightweight implementation  

---

## ğŸ› ï¸ Tech Stack
- **Python**  
- **OpenCV** â€“ for video capture & image processing  
- **Mediapipe** â€“ for hand landmark detection  
- **Scikit-learn / TensorFlow / Keras** â€“ for ML model training  
- **pyttsx3 / gTTS** â€“ for text-to-speech  

---

## ğŸ“‚ Project Structure
SL-Project/
â”‚-- data/ # Collected dataset of gestures
â”‚-- models/ # Trained ML models
â”‚-- main.py # Main script for real-time inference
â”‚-- inference_classifier.py # Gesture recognition module
â”‚-- requirements.txt # Dependencies
â”‚-- README.md # Project documentation

---


---

## âš™ï¸ Installation & Usage

### 1. Clone the repository
```bash
git clone https://github.com/<Sanchay-3011>/SL-Project.git
cd SL-Project
pip install -r requirements.txt
python main.py
```

---

ğŸ“Š Dataset

Custom dataset collected using hand gestures captured via webcam.

Includes Aâ€“Z alphabets and basic signs.

---

ğŸ¤ Contributing

Pull requests are welcome! If youâ€™d like to contribute, please fork the repo and submit a PR.

ğŸ“œ License

This project is licensed under the MIT License.

ğŸ‘©â€ğŸ’» Author

Sanchay Roy â€“ https://github.com/Sanchay-3011
